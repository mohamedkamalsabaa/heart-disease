{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87088422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV, \n",
    "                                    train_test_split, cross_val_score, StratifiedKFold)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, classification_report, confusion_matrix)\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f630e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594c7fa",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9081452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded selected features: (303, 10)\n",
      " Loaded target variable: (303,)\n",
      " Selected features: ['PC1', 'PC2', 'PC4', 'PC9', 'PC5', 'PC6', 'PC7', 'PC3', 'PC8', 'PC10']\n",
      " Target distribution: {0: 164, 1: 139}\n"
     ]
    }
   ],
   "source": [
    "# Load selected features and target\n",
    "X_selected = pd.read_csv('../Data/X_selected_features.csv')\n",
    "y = pd.read_csv('../Data/y_target.csv').squeeze()\n",
    "    \n",
    "print(f\" Loaded selected features: {X_selected.shape}\")\n",
    "print(f\" Loaded target variable: {y.shape}\")\n",
    "print(f\" Selected features: {list(X_selected.columns)}\")\n",
    "print(f\" Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806abcf",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 2. TRAIN-TEST SPLIT\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cd003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training set: 242 samples (79.9%)\n",
      " Test set: 61 samples (20.1%)\n",
      " Training target distribution: {0: 131, 1: 111}\n",
      " Test target distribution: {0: 33, 1: 28}\n"
     ]
    }
   ],
   "source": [
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\" Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_selected)*100:.1f}%)\")\n",
    "print(f\" Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X_selected)*100:.1f}%)\")\n",
    "print(f\" Training target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\" Test target distribution: {y_test.value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69705afe",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 3. BASELINE MODELS TRAINING\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training baseline models...\n",
      "   Training Logistic Regression...\n",
      "       CV Accuracy: 0.8224 (Â±0.0158)\n",
      "       Test Accuracy: 0.8852\n",
      "       Training Time: 0.004s\n",
      "   Training Decision Tree...\n",
      "       CV Accuracy: 0.7144 (Â±0.0584)\n",
      "       Test Accuracy: 0.7705\n",
      "       Training Time: 0.007s\n",
      "   Training Random Forest...\n",
      "       CV Accuracy: 0.8182 (Â±0.0202)\n",
      "       Test Accuracy: 0.8852\n",
      "       Training Time: 0.153s\n",
      "   Training SVM...\n",
      "       CV Accuracy: 0.8181 (Â±0.0355)\n",
      "       Test Accuracy: 0.8525\n",
      "       Training Time: 0.012s\n"
     ]
    }
   ],
   "source": [
    "# Define baseline models\n",
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "# Train and evaluate baseline models\n",
    "baseline_results = {}\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\" Training baseline models...\")\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv_strategy, scoring='accuracy')\n",
    "    \n",
    "    # Train on full training set\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'model': model,\n",
    "        'cv_accuracy_mean': cv_scores.mean(),\n",
    "        'cv_accuracy_std': cv_scores.std(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'test_auc': test_auc,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"       CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "    print(f\"       Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"       Training Time: {training_time:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc39c63",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 4. DEFINE HYPERPARAMETER GRIDS\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb76056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [3, 5, 7, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c8f61",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 5. HYPERPARAMETER TUNING\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86e89e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best baseline model: Logistic Regression (Test Accuracy = 0.8852)\n",
      "\n",
      " Performing GridSearchCV for Logistic Regression\n",
      "   Parameter grid: ['C', 'penalty', 'solver']\n",
      "    Running GridSearchCV (this may take a few minutes)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      " Hyperparameter Tuning Results:\n",
      "   Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
      "   Best CV Score: 0.8305\n",
      "   Baseline Accuracy: 0.8852\n",
      "   Tuned Accuracy: 0.8852\n",
      "   Improvement: +0.0000\n",
      "â„¹ No significant improvement from tuning.\n",
      "\n",
      " Final Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89        33\n",
      "           1       0.82      0.96      0.89        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.89      0.89      0.89        61\n",
      "weighted avg       0.90      0.89      0.89        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find best baseline model based on test accuracy\n",
    "best_model_name = max(baseline_results, key=lambda k: baseline_results[k]['test_accuracy'])\n",
    "best_result = baseline_results[best_model_name]\n",
    "\n",
    "print(f\" Best baseline model: {best_model_name} (Test Accuracy = {best_result['test_accuracy']:.4f})\")\n",
    "\n",
    "# Use selected feature set\n",
    "X_train_selected, X_test_selected = X_train, X_test\n",
    "y_train_selected, y_test_selected = y_train, y_test\n",
    "final_feature_names = X_train_selected.columns.tolist()\n",
    "\n",
    "if best_model_name in param_grids:\n",
    "    base_model = baseline_models[best_model_name]\n",
    "    param_grid = param_grids[best_model_name]\n",
    "\n",
    "    print(f\"\\n Performing GridSearchCV for {best_model_name}\")\n",
    "    print(f\"   Parameter grid: {list(param_grid.keys())}\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"    Running GridSearchCV (this may take a few minutes)...\")\n",
    "    grid_search.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "    best_tuned_model = grid_search.best_estimator_\n",
    "    y_pred_tuned = best_tuned_model.predict(X_test_selected)\n",
    "    accuracy_tuned = accuracy_score(y_test_selected, y_pred_tuned)\n",
    "\n",
    "    baseline_accuracy = best_result['test_accuracy']\n",
    "    improvement = accuracy_tuned - baseline_accuracy\n",
    "\n",
    "    print(f\"\\n Hyperparameter Tuning Results:\")\n",
    "    print(f\"   Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"   Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"   Baseline Accuracy: {baseline_accuracy:.4f}\")\n",
    "    print(f\"   Tuned Accuracy: {accuracy_tuned:.4f}\")\n",
    "    print(f\"   Improvement: {improvement:+.4f}\")\n",
    "\n",
    "    if improvement > 0.01:\n",
    "        print(\" Significant improvement achieved!\")\n",
    "        final_model = best_tuned_model\n",
    "        final_accuracy = accuracy_tuned\n",
    "    else:\n",
    "        print(\"â„¹ No significant improvement from tuning.\")\n",
    "        final_model = best_result['model']\n",
    "        final_accuracy = baseline_accuracy\n",
    "\n",
    "    print(f\"\\n Final Model Classification Report:\")\n",
    "    print(classification_report(y_test_selected, final_model.predict(X_test_selected)))\n",
    "\n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        final_importance = pd.DataFrame({\n",
    "            'feature': final_feature_names,\n",
    "            'importance': final_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        final_importance.plot(kind='barh', x='feature', y='importance',\n",
    "                              color='green', alpha=0.7, legend=False)\n",
    "        plt.title('Final Model Feature Importance', fontweight='bold')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\" No parameter grid defined for {best_model_name}\")\n",
    "    final_model = best_result['model']\n",
    "    final_accuracy = best_result['test_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24389da9",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# 6. SAVE FINAL MODEL\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19622f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final model saved to '../Models/final_heart_disease_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(final_model, '../Models/final_heart_disease_model.pkl')\n",
    "print(\" Final model saved to '../Models/final_heart_disease_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b7424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
